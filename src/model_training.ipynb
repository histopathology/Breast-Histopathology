{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import glob\nimport matplotlib.pylab as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport tensorflow as tf\nimport cv2\nimport math\nimport os\nimport random\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import backend as K\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom collections import defaultdict\n\n%env JOBLIB_TEMP_FOLDER=/tmp\nK.set_image_dim_ordering('tf')\nnp.random.seed(0)",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "neg_data_files = glob.glob(\"../input/IDC_regular_ps50_idx5/*/0/*.png\")\npos_data_files = glob.glob(\"../input/IDC_regular_ps50_idx5/*/1/*.png\")\nall_data_files = glob.glob(\"../input/IDC_regular_ps50_idx5/*/*/*.png\")\n\ndef process_data(num):\n    Y = []\n    X = []\n    pos_img = []\n    neg_img = []\n    counter = 0\n\n    for d in neg_data_files[:num]:\n        full_size_image = cv2.imread(d)\n        add = cv2.resize(full_size_image, (50, 50), interpolation = cv2.INTER_CUBIC)\n        X.append(add)\n        Y.append(0)\n        if counter < 5:\n            neg_img.append(add)\n        counter += 1\n        \n    counter = 0\n        \n    for d in pos_data_files[:num]:\n        full_size_image = cv2.imread(d)\n        add = cv2.resize(full_size_image, (50, 50), interpolation = cv2.INTER_CUBIC)\n        X.append(add)\n        Y.append(1)\n        if counter < 5:\n            pos_img.append(add)\n        counter += 1\n    \n    X = np.array(X).astype(np.float64)\n    Y = np.array(Y)\n    Y = to_categorical(Y)\n    \n    return X, Y, neg_img, pos_img\n\nX, Y, imgs0, imgs1 = process_data(15000)\n\nXtr, Xtest, Ytr, Ytest = train_test_split(X, Y, test_size = 0.2)\n\nprint(Xtr.shape)\nprint(Xtest.shape)",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e1443f2ced6dcc354b6183d8254198ad84e2275",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Drawing images helper functions\n\ndef select_random_indices(idc_type, x, y):\n    indices = []\n    \n    while len(indices) < 5:\n        index = random.randint(1, x.shape[0])\n        if idc_type == 0:\n            if np.argmax(y[index]) == 0:\n                indices.append(index)\n        elif idc_type == 1:\n            if np.argmax(y[index]) == 1:\n                indices.append(index)\n                \n    return indices\n\ndef get_images(ind_array, x):\n    images = []\n    for i in ind_array:\n        images.append(x[i].astype(np.uint8))\n    return images\n\ndef show_images(neg, pos):\n    for row in range(2):\n        plt.figure(figsize=(20, 10))\n        for col in range(5):\n            if row == 0:\n                plt.subplot(1,7,col+1)\n                plt.imshow(neg[col])\n                plt.axis('off')\n                plt.title(\"IDC(-)\")\n            else:\n                plt.subplot(1,7,col+1)\n                plt.imshow(pos[col])\n                plt.axis('off')\n                plt.title(\"IDC(+)\")",
      "execution_count": 72,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57bd13934514e08eeb1f4fb6a05f01963e4c3e0d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Images before pre-processing\")\n\n# Get random indices of negative and positive samples\nneg_ind = select_random_indices(0, Xtr, Ytr)\npos_ind = select_random_indices(1, Xtr, Ytr)\n\n# Get negative and positive image patches\nneg_imgs = get_images(neg_ind, Xtr)\npos_imgs = get_images(pos_ind, Xtr)\n\nshow_images(neg_imgs, pos_imgs)",
      "execution_count": 73,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61f16e0bffaab605249a805f0fbb3956be75c81f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Images after subtracting mean\")\n\n# Normalize data by subtracting mean\nmean_image = np.mean(Xtr)\nXtr -= mean_image\nXtest -= mean_image\n\n# Keep mean_image value for other jupyter notebook\nwith open('mean_image.txt', 'w') as file:\n    file.write(str(mean_image))\n\n# Get same images after normalization\nnorm_neg_imgs = get_images(neg_ind, Xtr)\nnorm_pos_imgs = get_images(pos_ind, Xtr)\n\nshow_images(norm_neg_imgs, norm_pos_imgs)",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcd04a4ccffda66a16906fde221588ed018c41ef",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def create_model(learn_rate):\n\n    model = Sequential()\n\n    model.add(Convolution2D(32, kernel_size=(3, 3), activation='relu', input_shape = (50, 50, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Convolution2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.50))\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dense(2, activation='softmax'))\n\n    opt = Adam(lr=learn_rate)\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=opt,\n                  metrics=['accuracy'])\n    \n    return model",
      "execution_count": 75,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "903af48db07f7f9304ccd024c32583c9527369e5",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "best_acc = float('-inf')\nbest_params = None\nbest_model = None\n\ndef find_hyperparams():\n    learn_rate = [5e-4, 5e-6, 1e-2]\n    epochs = [5, 10, 20, 40]\n    batch_size = [32, 64, 128]\n\n    for b in batch_size:\n        for e in epochs:\n            for lr in learn_rate:\n                model = create_model(lr)\n\n                model.fit(Xtr, Ytr, validation_data = (Xtest, Ytest),\n                              batch_size = b,\n                              epochs = e,\n                              shuffle = True)\n\n                scores = model.evaluate(Xtest, Ytest, verbose=0)\n\n                print('With parameters batch size = ' + str(b) + \", epochs = \" + str(e) + \", learn_rate = \" + str(lr))\n                print('Test loss:', scores[0])\n                print('Test accuracy:', scores[1])\n\n                if scores[1] > best_acc:\n                    print(\"New best model\")\n                    best_acc = scores[1]\n                    best_model = model\n                    best_params = [b, e, lr]\n\n    print(\"Best parameters: \", best_params)\n    best_model.save('best_model.h5')\n    \n    \nbest_model = create_model(5e-4)\nhistory = best_model.fit(Xtr, Ytr, validation_data = (Xtest, Ytest),\n              batch_size = 64,\n              epochs = 20,\n              shuffle = True)\n\nbest_model.save('best_model.h5')",
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc7cdf3def388cace8b363b136f8032620fd0dfe",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nscores = best_model.evaluate(Xtest, Ytest, verbose=0)\n\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n\nwith open('test_accuracy.txt', 'w') as file:\n    file.write(str(scores[1]))\n\nY_pred = best_model.predict(Xtest)\n\ndef create_cm(y_pred, y_actual):\n    err = defaultdict(int)\n    \n    for p in range(len(Y_pred)):\n        if (Y_pred[p][0] < Y_pred[p][1]) and np.argmax(y_actual[p]) == 0:\n            err[\"false_pos\"] += 1\n            \n        elif (Y_pred[p][0] > Y_pred[p][1]) and np.argmax(y_actual[p]) == 1:\n            err[\"false_neg\"] += 1\n\n        elif (Y_pred[p][0] < Y_pred[p][1]) and np.argmax(y_actual[p]) == 1:\n            err[\"true_pos\"] += 1\n            \n        elif (Y_pred[p][0] > Y_pred[p][1]) and np.argmax(y_actual[p]) == 0:\n            err[\"true_neg\"] += 1\n          \n    cm = [[err[\"true_neg\"], err[\"false_pos\"]], [err[\"false_neg\"], err[\"true_pos\"]]]\n    return cm\n\ndef show_conf_matrix(cm):\n    plt.clf()\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel1)\n    classNames = ['IDC (-)','IDC (+)']\n    plt.title('IDC (-) and IDC (+) Confusion Matrix')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=45)\n    plt.yticks(tick_marks, classNames)\n    s = [['TN','FP'], ['FN', 'TP']]\n    for i in range(2):\n        for j in range(2):\n            plt.text(j, i, str(s[i][j]) + \" = \" + str(cm[i][j]), horizontalalignment=\"center\")\n    plt.show()\n    \nconf_matrix = create_cm(Y_pred, Ytest)\nshow_conf_matrix(conf_matrix)",
      "execution_count": 77,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11503a4e63238e5abf92fc908858d3d47a39aaae",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def score_IDC(model, patient_no):\n    data_files = glob.glob(\"../input/IDC_regular_ps50_idx5/\" + str(patient_no) + \"/*/*.png\")\n    X = []\n    Y = []\n\n    for d in data_files:\n        full_size_image = cv2.imread(d)\n        X.append(cv2.resize(full_size_image, (50, 50), interpolation = cv2.INTER_CUBIC))\n        if d.endswith(\"class0.png\"):\n            Y.append(0)\n        else:\n            Y.append(1)\n            \n    X = np.array(X, dtype=np.float64)\n    X -= mean_image\n    \n    Y_pred = model.predict(X)\n    pos = 0.0\n    err = defaultdict(int)\n    for p in range(len(Y_pred)):\n        if Y_pred[p][0] < Y_pred[p][1]:\n            pos += 1.0\n        if (Y_pred[p][0] < Y_pred[p][1]) and Y[p] == 0:\n            err[\"false_pos\"] += 1\n        elif (Y_pred[p][0] > Y_pred[p][1]) and Y[p] == 1:\n            err[\"false_neg\"] += 1\n            \n    score = pos / float(len(Y_pred))\n    print(\"Patient: {} --> IDC aggressiveness score: {:0.4F}\".format(patient_no, score))\n    return score, err\n\nscore, err = score_IDC(best_model, 16896)\n\nprint(\"False positives: \" + str(err[\"false_pos\"]))\nprint(\"False negatives: \" + str(err[\"false_neg\"]))\n",
      "execution_count": 78,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}